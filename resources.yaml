---
# Global configuration of computing nodes.
images:
  default: vgcn~rockylinux-9-latest-x86_64~+generic+workers+internal~20240321~66731~HEAD~60854e6
  gpu: vgcn~rockylinux-9-latest-x86_64~+generic+workers-gpu+internal~20240327~34401~HEAD~2a80ce3
  secure: vggp-v60-secure-j322-692e75a7c101-main

network: bioinf
secgroups:
  - ufr-ingress
  # interactive-egress: A reduced more stringent egress rule for all nodes
  - interactive-egress
sshkey: cloud3
pubkeys:
  # The public key(s) that will be accepted when SSHing to a machine.
  - "AAAAB3NzaC1yc2EAAAABIwAAAQEAuSG1VOumQhbJfOyalJjS4lPC8eeeL02ld/VI2BFApyMfwbB1QxehY3lMBXt/cBTzqU3MxgJQVzNr/AgjHa5rKn2hSGMfKAdaX2tG686k715bBjRm9rJNhmc8KSH9tVS35M0HwRXMfiGvSmb5qJ6utWRZe6RM2JMIbqqI5Oc4tbzPPVKk1+yvT1JdYuyqAOp2yvQbOqKaXmqOhPdPNaJZMI4o+UHmmb8FH6OTDY27G7X7u07ZPwVi1j+6ZFVMQZqg1RhUdg9kmHpHwMX7P6NcD4G9GsISHIh92eva9xgWYGiS0wUsmOWTNgAzzsfRZjMFep+jB2wup6QN7XpMw97eTw=="

# Behavior of `synchronize.py''
graceful: false

nodes_inventory:
  c1.c28m225d50: 5 #(16.04.2024: RZ swapped the underlying servers for a 4 in 1 node and this will be of a different flavor and we need to wait to get the hardware)
  c1.c28m475d50: 19
  c1.c36m100d50: 30
  c1.c36m225d50: 15
  c1.c36m900d50: 1
  c1.c36m975d50: 8
  c1.c60m1975d50: 1
  c1.c120m225d50: 12
  c1.c120m425d50: 22
  c1.c125m425d50: 16
  c1.c28m935d50: 4
  c1.c28m875d50: 2
  g1.c14m40g1d50: 4
  g1.c8m40g1d50: 4

deployment:
  # worker-c120m225:
  #   count: 1 #12
  #   flavor: c1.c120m225d50
  #   group: compute
  #   docker: true
  #   image: default
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: hard
  #     mem_reserved_size: 2048

  # worker-fetch:
  #   count: 0
  #   flavor: c1.c36m100d50
  #   group: upload
  #   image: default

  worker-interactive:
    count: 3 #8
    flavor: c1.c36m100d50
    group: interactive
    docker: true
    image: default
    volume:
      size: 1024
      type: default
  worker-c28m475:
    count: 19
    flavor: c1.c28m475d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  worker-c28m225:
    count: 0
    flavor: c1.c28m225d50
    group: compute # compute_test
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  worker-c36m100:
    count: 25
    flavor: c1.c36m100d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  worker-c36m225:
    count: 15
    flavor: c1.c36m225d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  worker-c36m900:
    count: 1 #1 it's a c1.c36m975d50 host with probably a faulty memory bank
    flavor: c1.c36m900d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: default

  worker-c36m975:
    count: 8
    flavor: c1.c36m975d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: default

  # 24.04.2024: Flavors c1.c28m935d50 and c1.c28m875d50 will be available once
  # moved to the new cloud along with the GPU flavors.
  # worker-c28m935:
  #   count: 4 #4
  #   flavor: c1.c28m935d50
  #   group: compute
  #   docker: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: soft
  #     mem_reserved_size: 2048
  #   image: default

  # worker-c28m875:
  #   count: 2 #2
  #   flavor: c1.c28m875d50
  #   group: compute
  #   docker: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: soft
  #     mem_reserved_size: 2048
  #   image: default

  worker-c64m2:
    count: 1
    flavor: c1.c60m1975d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    image: default

  # worker-c120m225:
  #   count: 12 #12
  #   flavor: c1.c120m225d50
  #   group: compute
  #   docker: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: hard
  #     mem_reserved_size: 2048
  #   image: default

  worker-c120m425:
    count: 18 #22
    flavor: c1.c120m425d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  worker-c125m425:
    count: 16 #16
    flavor: c1.c125m425d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: default

  # 24.04.2024: GPU VMs are deployed (manually) in the old cloud for now
  # worker-c14m40g1:
  #   count: 4 #4
  #   flavor: g1.c14m40g1d50
  #   group: compute_gpu
  #   docker: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: soft
  #     mem_reserved_size: 1024
  #   image: gpu

  # worker-c8m40g1:
  #   count: 4 #4
  #   flavor: g1.c8m40g1d50
  #   group: compute_gpu
  #   docker: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: soft
  #     mem_reserved_size: 1024
  #   image: gpu

  # Trainings
  # These will overlap April 8-17
  # training-kmb6:
  #   count: 1
  #   flavor: c1.c28m225d50
  #   start: 2024-03-01
  #   end: 2024-05-17
  #   group: training-kmb615
  #   image: default
  # training-tp-m:
  #   count: 2
  #   flavor: c1.c28m225d50
  #   start: 2024-03-26
  #   end: 2024-04-17
  #   group: training-tp-master1-chip-seq
  #   image: default
  # training-geno:
  #   count: 2
  #   flavor: c1.c28m225d50
  #   start: 2024-05-07
  #   end: 2024-05-10
  #   group: training-genome-assembly-2024
  #   image: default
  # training-nort:
  #   count: 2
  #   flavor: c1.c28m225d50
  #   start: 2024-06-07
  #   end: 2024-06-07
  #   group: training-northumbria-7jun24
  #   image: default
  # training-joca:
  #   count: 2
  #   flavor: c1.c28m225d50
  #   start: 2024-04-12
  #   end: 2024-04-12
  #   group: training-joca-epigenomics-24
  #   image: default
  # training-woco:
  #   count: 1
  #   flavor: c1.c28m225d50
  #   start: 2024-04-08
  #   end: 2024-05-10
  #   group: training-woco2024
  #   image: default
  # training-e502:
  #   count: 2
  #   flavor: c1.c28m225d50
  #   start: 2024-04-09
  #   end: 2024-04-09
  #   group: training-e5020-2024-04-09
  #   image: default
  training-denb:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-05-15
    end: 2024-05-15
    group: training-denbi-genomics
  training-sunu:
    count: 4
    flavor: c1.c28m225d50
    start: 2024-05-28
    end: 2024-05-31
    group: training-sunu-dbs-prac3-2024
  training-mtb-:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-06-10
    end: 2024-06-14
    group: training-mtb-ngs-2024
  training-fr-j:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-06-17
    end: 2024-06-21
    group: training-fr-june24
  training-frju:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-07-22
    end: 2024-07-26
    group: training-fr-july-24
  training-prac:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-07-16
    end: 2024-07-19
    group: training-prac5-sunu-2024
  training-ghos:
    count: 1
    flavor: c1.c28m225d50
    start: 2024-06-18
    end: 2024-06-18
    group: training-ghoshd
  training-rnas:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-08-28
    end: 2024-08-31
    group: training-rnaseq
